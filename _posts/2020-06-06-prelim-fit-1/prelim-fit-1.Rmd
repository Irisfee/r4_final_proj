---
title: "Prelim fit 1"
description: |
  A short description of the post.
author:
  - name: Bernice, Peeta, Yufei
    url: https://irisfee.github.io/r4_final_proj/posts/2020-06-06-prelim-fit-1/
date: 06-06-2020
output:
  distill::distill_article:
    self_contained: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE)
```
# Read in the data
* Details about the data can be found in another post

```{r}
library(tidyverse)

full_train <- read_csv(here::here("data", "final_merged_training.csv"),
                       col_types = cols(.default = col_guess())) 
```

# Split the data
* Select only 1% of the full training dataset to reduce running time
* Split the training dataset with `ethinic_cd` as the stratified variable. Following the default setting, 3/4 of the data is included in the `math_train` and the other 1/4 is included in `math_test`
* Create 10-fold cross-validation `math_cv`. Again, use `ethinic_cd` as the stratified variable
* We use linear regression as the model
```{r}

library(tidymodels)
math <- full_train %>% 
  sample_frac(.01)

math_split <- initial_split(math, strata = "ethnic_cd")

math_train <- training(math_split) 
math_test <- testing(math_split)

math_cv <- vfold_cv(math_train, strata = "ethnic_cd")

mod <- linear_reg()  %>% 
  set_mode("regression")  %>% 
  set_engine("lm")
```

# Create the receipe



The recipe sets six variables to be ID variables, rather than predictors or outcomes, transforms the tst_dt variable to be an actual date, rather than character, assigns an "unknown" level to gndr, ethnic_cd, calc_amdn_cd, and all other nominal variables with missing data, imputes enrl_grd, lat, lon, and all other numeric variables with their median value, removes calc_admn_cd for zero variance, dummy codes gndr, ethnic_cd, and all other nomial predictor variables, and removes near-zero variance predictors such as gndr_unkown, and ethnic_cd_B (the dummy code for students coded Black).

```{r}
ggplot(math_train, aes(lat, score)) +
  geom_smooth()
ggplot(math_train, aes(lon, score)) +
  geom_smooth()
math_train %>% 
  mutate(tst_dt =lubridate::mdy_hms(tst_dt)) %>% 
  mutate(tst_dt = as.numeric(tst_dt)) %>% 
  ggplot(aes(tst_dt, score)) +
  geom_smooth()
```


```{r}
rec <- recipe(score ~ ., data = math_train)  %>% 
  step_mutate(tst_dt = lubridate::mdy_hms(tst_dt),
              tst_dt_num = as.numeric(tst_dt)) %>%
  update_role(tst_dt, new_role = "time_index")  %>% 
  update_role(contains("id"), ncessch, sch_name, new_role = "id vars")  %>% 
  step_novel(all_nominal())  %>% 
  step_unknown(all_nominal())  %>% 
  step_medianimpute(all_numeric(), -all_outcomes(), -has_role("id vars"))  %>% 
  step_nzv(all_predictors(), freq_cut = 0, unique_cut = 0) %>% 
  step_dummy(all_nominal(), -tst_dt)  %>% 
  step_nzv(all_predictors())  %>% 
  step_ns(lat, deg_free = 10)  %>% 
  step_ns(lon, deg_free = 9) %>%
  step_ns(tst_dt_num, deg_free = 7)  %>%
  step_interact(terms = ~ enrl_grd:contains("sp_ed_fg"))%>% 
  step_interact(terms = ~ starts_with("ethnic"):ends_with("prop"))
```

```{r}

rec %>% prep()


```

```{r}

```


```{r}



geo_params <- 
  refined_rec2 %>% 
  parameters() %>% 
  update(tune_lat = spline_degree(), 
         tune_lon = spline_degree(),
         tune_dt  = spline_degree())

spline_grid <- grid_max_entropy(geo_params, size = 50)
```


```{r}
tune_mod <- linear_reg(penalty = tune(), mixture = tune())  %>% 
  set_mode("regression")  %>% 
  set_engine("glmnet")  

grid_to_tune <- grid_regular(penalty(), mixture(), levels = 25)

enet_tune <- tune_grid(
  tune_mod,
  refined_rec3,
  cv, 
  grid = grid_to_tune,
  control = control_resamples(verbose = TRUE)
)
```

